Step: 0 | loss: 0.66363 | acc: 0.74077 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 2 | loss: 0.60052 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 4 | loss: 0.52532 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 6 | loss: 0.45803 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 8 | loss: 0.40601 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 10 | loss: 0.36994 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 12 | loss: 0.34709 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 14 | loss: 0.33378 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 16 | loss: 0.32673 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 18 | loss: 0.32351 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 20 | loss: 0.32250 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 22 | loss: 0.32267 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 24 | loss: 0.32341 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 26 | loss: 0.32434 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 28 | loss: 0.32527 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 30 | loss: 0.32611 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 32 | loss: 0.32679 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 34 | loss: 0.32732 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 36 | loss: 0.32770 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 38 | loss: 0.32794 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 40 | loss: 0.32806 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 42 | loss: 0.32809 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 44 | loss: 0.32803 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 46 | loss: 0.32791 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 48 | loss: 0.32773 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 50 | loss: 0.32752 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 52 | loss: 0.32728 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 54 | loss: 0.32702 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 56 | loss: 0.32675 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 58 | loss: 0.32647 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 60 | loss: 0.32620 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 62 | loss: 0.32592 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 64 | loss: 0.32565 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 66 | loss: 0.32539 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 68 | loss: 0.32514 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 70 | loss: 0.32490 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 72 | loss: 0.32468 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 74 | loss: 0.32446 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 76 | loss: 0.32426 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 78 | loss: 0.32407 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 80 | loss: 0.32390 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 82 | loss: 0.32373 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 84 | loss: 0.32358 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 86 | loss: 0.32345 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 88 | loss: 0.32332 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 90 | loss: 0.32321 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 92 | loss: 0.32310 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 94 | loss: 0.32301 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 96 | loss: 0.32292 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 98 | loss: 0.32284 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 100 | loss: 0.32277 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 102 | loss: 0.32271 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 104 | loss: 0.32266 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 106 | loss: 0.32261 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 108 | loss: 0.32256 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 110 | loss: 0.32252 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 112 | loss: 0.32249 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 114 | loss: 0.32246 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 116 | loss: 0.32243 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 118 | loss: 0.32241 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 120 | loss: 0.32239 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 122 | loss: 0.32237 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 124 | loss: 0.32236 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 126 | loss: 0.32234 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 128 | loss: 0.32233 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 130 | loss: 0.32232 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 132 | loss: 0.32231 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 134 | loss: 0.32230 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 136 | loss: 0.32230 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 138 | loss: 0.32229 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 140 | loss: 0.32229 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 142 | loss: 0.32228 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 144 | loss: 0.32228 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 146 | loss: 0.32228 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 148 | loss: 0.32227 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 150 | loss: 0.32227 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 152 | loss: 0.32227 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 154 | loss: 0.32227 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 156 | loss: 0.32227 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 158 | loss: 0.32227 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 160 | loss: 0.32227 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 162 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 164 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 166 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 168 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 170 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 172 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 174 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 176 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 178 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 180 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 182 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 184 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 186 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 188 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 190 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 192 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 194 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 196 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 198 | loss: 0.32226 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
