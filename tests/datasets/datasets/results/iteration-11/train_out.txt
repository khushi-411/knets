Step: 0 | loss: 0.13450 | acc: 0.33949 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 2 | loss: 0.08153 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 4 | loss: 0.05035 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 6 | loss: 0.04455 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 8 | loss: 0.04527 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 10 | loss: 0.04641 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 12 | loss: 0.04720 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 14 | loss: 0.04770 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 16 | loss: 0.04802 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 18 | loss: 0.04823 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 20 | loss: 0.04837 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 22 | loss: 0.04847 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 24 | loss: 0.04854 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 26 | loss: 0.04858 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 28 | loss: 0.04862 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 30 | loss: 0.04864 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 32 | loss: 0.04865 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 34 | loss: 0.04866 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 36 | loss: 0.04867 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 38 | loss: 0.04867 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 40 | loss: 0.04867 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 42 | loss: 0.04866 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 44 | loss: 0.04865 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 46 | loss: 0.04864 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 48 | loss: 0.04863 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 50 | loss: 0.04862 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 52 | loss: 0.04861 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 54 | loss: 0.04859 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 56 | loss: 0.04858 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 58 | loss: 0.04856 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 60 | loss: 0.04854 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 62 | loss: 0.04852 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 64 | loss: 0.04850 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 66 | loss: 0.04848 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 68 | loss: 0.04846 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 70 | loss: 0.04844 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 72 | loss: 0.04841 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 74 | loss: 0.04838 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 76 | loss: 0.04836 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 78 | loss: 0.04833 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 80 | loss: 0.04830 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 82 | loss: 0.04826 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 84 | loss: 0.04823 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 86 | loss: 0.04819 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 88 | loss: 0.04815 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 90 | loss: 0.04811 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 92 | loss: 0.04807 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 94 | loss: 0.04802 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 96 | loss: 0.04797 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 98 | loss: 0.04791 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 100 | loss: 0.04786 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 102 | loss: 0.04779 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 104 | loss: 0.04773 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 106 | loss: 0.04766 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 108 | loss: 0.04758 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 110 | loss: 0.04750 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 112 | loss: 0.04742 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 114 | loss: 0.04732 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 116 | loss: 0.04723 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 118 | loss: 0.04712 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 120 | loss: 0.04701 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 122 | loss: 0.04689 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 124 | loss: 0.04677 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 126 | loss: 0.04665 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 128 | loss: 0.04652 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 130 | loss: 0.04639 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 132 | loss: 0.04626 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 134 | loss: 0.04613 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 136 | loss: 0.04600 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 138 | loss: 0.04587 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 140 | loss: 0.04575 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 142 | loss: 0.04563 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 144 | loss: 0.04553 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 146 | loss: 0.04542 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 148 | loss: 0.04533 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 150 | loss: 0.04525 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 152 | loss: 0.04517 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 154 | loss: 0.04511 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 156 | loss: 0.04505 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 158 | loss: 0.04499 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 160 | loss: 0.04494 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 162 | loss: 0.04489 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 164 | loss: 0.04484 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 166 | loss: 0.04479 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 168 | loss: 0.04475 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 170 | loss: 0.04471 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 172 | loss: 0.04467 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 174 | loss: 0.04464 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 176 | loss: 0.04461 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 178 | loss: 0.04458 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 180 | loss: 0.04456 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 182 | loss: 0.04454 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 184 | loss: 0.04452 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 186 | loss: 0.04451 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 188 | loss: 0.04450 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 190 | loss: 0.04449 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 192 | loss: 0.04449 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 194 | loss: 0.04449 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 196 | loss: 0.04449 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
Step: 198 | loss: 0.04449 | acc: 0.90128 | precision: 0.00000 | recall: 91.30002 | specificity: 91.30002 | f1_score: 91.30002
